{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b08e7fe",
   "metadata": {},
   "source": [
    "## Exact Match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70189af0",
   "metadata": {},
   "source": [
    "The exact match metric measures the accuracy of the answers if the answer match exactly the EM score is 1\n",
    "else the EM score is 0 its easy to use but not the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aaf52cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example\n",
    "predicted_answers=[\"Yes\",\"France is the capital\",\"It is true\",\"The capital of india is Delhi\"]\n",
    "actual_answers=[\"yes\",\"The capital is  France\",\"It is false\",\"The capital of india is Delhi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d06cab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1]\n",
      "25.0\n"
     ]
    }
   ],
   "source": [
    "em=[] #Initializing a list\n",
    "for  i in range(len(predicted_answers)):\n",
    "    if predicted_answers[i]==actual_answers[i]:\n",
    "        em.append(1) #Append 1 if match is there \n",
    "    else:\n",
    "        em.append(0)  #Append 0 if there is no match\n",
    "print(em)\n",
    "em_accuracy=(sum(em)/len(em))*100\n",
    "print(em_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c901ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conta\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Comparing using un necessary letters\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "236ff458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(predicted_sentence,actual_sentence):\n",
    "    #Cleaning predicted  sentence\n",
    "    predicted_sentence=predicted_sentence.lower()\n",
    "    word_tokens=word_tokenize(predicted_sentence)\n",
    "    global stop_words\n",
    "    stop_words=stopwords.words(\"english\")\n",
    "    predicted_modified=[word for word in word_tokens if word not in stop_words]\n",
    "    \n",
    "    #Cleaning actual sentence\n",
    "    \n",
    "    actual_sentence=actual_sentence.lower()\n",
    "    word_tokens2=word_tokenize(actual_sentence)\n",
    "    actual_modified=[word2 for word2 in word_tokens2 if word2 not in stop_words]\n",
    "    \n",
    "    \n",
    "    predicted_modified=re.sub(\"[^0-9a-z ]\",\"\",''.join(predicted_modified))\n",
    "    actual_modified=re.sub(\"[^0-9a-z ]\",\"\",''.join(actual_modified))\n",
    "    \n",
    "    if predicted_modified==actual_modified:\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a73ab72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n"
     ]
    }
   ],
   "source": [
    "modified_em=[] #Initializing a list\n",
    "for  i in range(len(predicted_answers)):\n",
    "    if evaluation(predicted_answers[i],actual_answers[i])==1:\n",
    "        modified_em.append(1) #Append 1 if match is there \n",
    "    else:\n",
    "        modified_em.append(0)  #Append 0 if there is no match\n",
    "mod_em_accuracy=(sum(modified_em)/len(modified_em))*100\n",
    "print(mod_em_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9424230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 1.0, 'p': 0.5, 'f': 0.6666666622222223},\n",
       "  'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "  'rouge-l': {'r': 1.0, 'p': 0.5, 'f': 0.6666666622222223}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ROUGE technique-->Recall Oriented Understudy for Gisting Evaluation\n",
    "from rouge import Rouge\n",
    "#Example\n",
    "predicted=\"hello to the world\"\n",
    "actual=\"hello world\"\n",
    "\n",
    "rouge=Rouge()\n",
    "\n",
    "rouge.get_scores(predicted,actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d362be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.6041666666666666,\n",
       "  'p': 0.6041666666666666,\n",
       "  'f': 0.6041666629166667},\n",
       " 'rouge-2': {'r': 0.375, 'p': 0.375, 'f': 0.3749999975},\n",
       " 'rouge-l': {'r': 0.47916666666666663,\n",
       "  'p': 0.47916666666666663,\n",
       "  'f': 0.4791666629166667}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "rouge=Rouge()\n",
    "rouge.get_scores(predicted_answers,actual_answers,avg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5877dd34",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5994565",
   "metadata": {},
   "source": [
    "Cosine similarity is a measure used to determine how similar two vectors are in a high-dimensional space. It measures the cosine of the angle between the vectors and is often used in natural language processing and information retrieval tasks to compare the similarity of documents or sentences represented as numerical vectors.   \n",
    "Refer Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bde1e5f3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conta\\anaconda3\\lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "WARNING:tensorflow:From C:\\Users\\conta\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[[0.30015612 0.53977    0.93893063 0.7675121 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sentences = [\"France is the capital\", \"It is true\", \"The capital of India is Delhi\", \"The capital is France\", \"France\"]\n",
    "model_name = \"bert-base-nli-mean-tokens\"\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Encode the sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Convert the first embedding to a numpy array with shape (1, d)\n",
    "first_embedding = np.array([embeddings[0]])\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity = cosine_similarity(first_embedding, embeddings[1:])\n",
    "\n",
    "print(similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6181f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
